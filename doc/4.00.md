IV. Advanced Design and Analysis Techniques
===========================================

This part covers three important techniques using in designing and analyzing efficient algorithms: dynamic programming, greedy algorithms, and amortized analysis.
Earlier parts have presented other widely applicable and useful techniques, such as divide-and-conquer, randomization, and how to solve recurrences.
The techniques presented here are somewhat more sophisticated, but they help us attack many computational problems.
These techniques will recur later in the book.

Dynamic programming typically applies to optimization problems in which we make a set of choices to arrive at an optimal solution.
As we make each choice, subproblems of the same form often arise.
Dynamic programming is effective when a given subproblem may arise from more than one partial set of choices; the key technique is to store the solution to each subproblem in case it should reappear.
[Chapter 15](4.15.md) shows how this simple idea can sometimes transform exponential-time algorithms into polynomial-time algorithms.

Like dynamic programming, greedy algorithms typically apply to optimization problems in which we make a set of choices to arrive at an optimal solution.
The idea of a greedy algorithm is to make a choice in a locally optimal manner.
A simple exchange is coin-changing: to minimize the number of U.S. coins needed to make change for a given amount, we can repeatedly select the largest-denomination coin that is not larger than the amount that remains.
A greedy approach provides an optimal solution for many such problems much faster than a dynamic-programming approach would.
We cannot always tell if a greedy approach will be effective, however.
[Chapter 16](4.16.md) introduces matroid theory, which provides a mathematical basis that can help us to show that a greedy algorithm yields an optimal solution.

We use amortized analysis to analyze certain algorithms that perform a sequence of similar operations.
Instead of bounding the cost of the sequence of operations by bounding the actual cost of each operation separately, an amortized analysis provides a bound on the actual cost of the entire sequence.
One advantage of this approach is that although some operations might be expensive, many others might be cheap.
In other words, many of the operations might run well under the worst-case time.
Amortized analysis is not just an analysis tool, however; it is also a way of thinking about the design of algorithms, since the design of an algorithm and the analysis of its running time are often closely intertwined.
[Chapter 17](4.17.md) introduces three ways to perform an amortized analysis of an algorithm.


[Chapter 15](4.15.md) introduces dynamic programming.

[Chapter 16](4.16.md) introduces greedy algorithms.

[Chapter 17](4.17.md) introduces amortized analysis.

